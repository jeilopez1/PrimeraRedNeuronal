# -*- coding: utf-8 -*-
"""PrimeraRedNeuronal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PeHsIuAhoVv6o9qTYcHyb4m6toQI_itY
"""

import numpy as np
import scipy as sc
import matplotlib.pyplot as plt
import time
from IPython.display import clear_output

from sklearn.datasets import make_circles

#crear el data set 
n =500
p= 2
X,Y=make_circles(n_samples=n, factor=0.5, noise=0.05)
plt.scatter(X[Y==0,0],X[Y==0,1],c="skyblue")
plt.scatter(X[Y==1,0],X[Y==1,1],c="salmon")
plt.axis("equal")
plt.show()


Y=Y[:,np.newaxis]

sigm =(lambda x: 1/(1+np.e**(-x)),
       lambda x: x * (1-x))

_X=np.linspace(-10,11, 1000)
plt.plot(_X,sigm[1](_X))

class neural_layer():
    def __init__(self, n_conn,n_neur, act_f):
        self.act_f=act_f
        self.b=np.random.rand(1, n_neur)*2-1
        self.W=np.random.rand(n_conn, n_neur)*2-1

l0 = neural_layer(p,4,sigm) ## n_conn,n_neur, act_f
l1 =neural_layer(4,8, sigm)



def create_nn(topology, act_f):
  nn=[]
  for l,layer in enumerate(topology[:-1]):
    nn.append(neural_layer(topology[l],topology[l+1],act_f))
  return nn

topology =[p,4,8,1]

neural_net=create_nn(topology, sigm)



l2_cost =(lambda Yp, Yr: np.mean((Yp -Yr)**2),
          lambda Yp, Yr: (Yp-Yr))


def train(neural_net, X,Y,l2_cost,lr =0.5, train=True):
  out=[(None,X)]
  #forward pass
  for l,layer in enumerate(neural_net):
    
    z = out[-1][1] @ neural_net[l].W + neural_net[l].b
    
    a= neural_net[l].act_f[0](z)
    out.append((z,a))

  if(train):
    deltas =[]
    for l in reversed(range(0, len(neural_net))):
      z=out[l+1][0]
      a=out[l+1][1]
      if l== len(neural_net)-1:

        #calcular delta ultima capa
        deltas.insert(0,l2_cost[1](a,Y)*neural_net[l].act_f[1](a))
      else:
        deltas.insert(0,deltas[0] @ _W.T *neural_net[l].act_f[1](a))

      _W=neural_net[l].W
      neural_net[l].b= neural_net[l].b - np.mean(deltas[0],axis=0,keepdims=True)*lr
      neural_net[l].W= neural_net[l].W-out[l][1].T @ deltas[0]*lr
  return out[-1][1]

xxx=train(neural_net,X,Y,l2_cost,0.5)

neural_n= create_nn(topology,sigm)

loss=[]
count=0

fig = plt.figure()
fig.tight_layout()
for i in range(2500):
  pY=train(neural_n,X,Y,l2_cost,lr=0.05)
    
  if i % 25 == 0:
    
    loss.append(l2_cost[0](pY,Y))
    print(loss[len(loss)-1])
    res=50

    _x0 = np.linspace(-1.5,1.5,res)
    _x1 = np.linspace(-1.5,1.5,res)

    _Y=np.zeros((res,res))

    for i0, x0 in enumerate(_x0):

    
      for i1, x1 in enumerate(_x1):
        count=count+1
        _Y[i0,i1] = train(neural_n, np.array([[x0,x1]]),Y,l2_cost,train=False)[0][0]
    
    ax= plt.subplot(1,2,1)
    ax.pcolormesh(_x0,_x1,_Y,cmap="coolwarm")
    ax.axis("equal")
    

    ax.scatter(X[Y[:,0]==0,0],X[Y[:,0]==0,1],c="skyblue")
    ax.scatter(X[Y[:,0]==1,0],X[Y[:,0]==1,1],c="salmon")
    
    clear_output(wait=True)
    ax2= plt.subplot(1,2,2)
    ax2.plot(range(len(loss)),loss)
    plt.draw() 
    #plt.show()
    #time.sleep(0.5)
    plt.pause(0.2)
    fig.clear()